# Создание современных приложений на базе Quarkus
Документ описывает создание демонстрационного приложения, включающего следующие возможности:
- создание проекта из шаблона (project bootstrapping)
- элементы реактивного программирования (reactive programming)
- интеграцию с сетью данных (datagrid)
- компиляция в родной для процессора машинный код
- развертывание на OpenShift
- конвейер Tekton
- матрики и тесты доступности приложения и его модулей (health & metrics)
- бессерверные приложения (serverless)
- управление жизненным циклом с помощью оператора Kubernetes
- взаимодействие с фронтенд приложением через шину сообщений

Документ, представляющий собой учебник, разделен на главы, описывающие конкретные возможности, 
фрагменты кода, строки которых начинаются со знака доллара ($) приведен в качестве примера и 
необходимости их выполнять нет. Фрагменты без знака доллара вначале предполагают их выполнение. 
Исходный код проекта доступен по адресу https://github.com/e2e-openshift-demos/quarkus-demo, для 
удобства каждая глава выделена в одельную ветку.

В учебнике будет использоваться современный фремворк Quarkus (https://quarkus.io), сочетающий
в себе удобство использования, скорость работы и большое количество интеграций, реализованных 
через дополнения, устанавливающихся одной командой maven или плагином IDE. Практически по каждой 
главе данного учебника можно найти пример в той или иной мере отражающей просиходящее. Фреймворк 
основан на Eclipse Vert.x, а для оптимизированных для работы в облачных средах приложений Graal VM, 
как средство компиляции не в байт-, а в родной для процессора машинный код. Имеет расширения для 
работы с БД, в том числе и поддерживает Panache, расширения для работы с серверами единого входа (SSO),
распределенными вычислительными сетями (Datagrid), поддерживает из коробки работу с HTTP/2, в том 
числе и gRPC, серверами очередей (Kafka, AMQ) и т.д.

В качестве среды выполнения будет использоваться Red Hat OpenShift, в реализации для разработчика - 
CodeReady Containers. Подробнее о развертывании и экосистеме CodeReady можно ознакомиться на 
тематическом канале https://www.youtube.com/playlist?list=PLs7J8aLRDSawqWHGs8XIPhL1lpjrB6Dpn.

## Глава 1 - Создание проекта из шаблона

Quarkus имеет встроенную возможность создание проекта по шаблону, как например показано ниже
```
$ mvn io.quarkus:quarkus-maven-plugin:1.6.0.Final:create \
    -DprojectGroupId=org.acme \
    -DprojectArtifactId=config-quickstart \
    -DclassName="org.acme.config.GreetingResource" \
    -Dpath="/greeting"
```
Но часто бывает необходимо для определенных групп проектов иметь дополнительные настройки и конфигурацию.
А таком случае изначальный шаблон дорабатывается. 

Дополнительно, существует проект сообщества, и существует промышленная сборка от Red Hat. Первый вариант
имеет больше возможностей, может быть не всегда хорошо протестированных и с не всегда понятным будущим, 
в то время как второй имеет гарантию поддерживаемости не включает возможности, будущее которых сомнительно.

Таким образом для создания проекта, необходимо использовать генератор типа, реализованного как дополнение 
Maven. В нашем случае будем использовать shell-скрипт, как показано ниже:

```
export WS=~/src/openshift-demos
mkdir -p $WS && cd $WS
git clone https://github.com/e2e-openshift-demos/bootstrap
mkdir -p quarkus-demo && cd quarkus-demo
USE_REDHAT=false $WS/bootstrap/quarkus/bin/quarkus.sh
```
Будет создан проект quarkus-demo и ресурс Greeting API, всеми параметрами можно управлять через переменные 
окружения, в данном случае использовался шаблон и ссылка на Quarkus от сообщества. Проверить работоспособность 
очень просто, запустив Quarkus приложение Greeting в режиме разработчика, позволяющего выполнять, так 
называемое живое кодирование, то есть изменение Java-кода без необходимости пересборки нового запуска.

Проверим, что получилось, но для дальнейшего использования и доработок, имеет смысл переименовать каталог 
проекта в `app’

``` 
mv quarkus-demo app && cd app
mvn quarkus:dev
```
Дождитесь загрузки приложения и откройте его в браузере по адресу http://127.0.0.1:8080/hello. Браузер должен
 показать страницу с единственным словом `hello’  После чего вернитесь в терминал и остановите приложение, 
 нажав комбинацию клавиш CTRL+C.

Исходный код, готовый к сборке и запуску находится в ветке b-step-01 репозитория https://github.com/e2e-openshift-demos/quarkus-demo. 

## Глава 2 - создание защищенного подключения

Стандартом de facto в современном мире является использование защищенных соединений везде. Вообще везде. 
Не только между браузером и фронт-ендом, или при соединении с партнерскими, но и между всеми внутренними сервисами, 
включая и соединения с БД и другими источниками данных. Есть различные подходы для реализации этой стратегии, 
один из набирающих популярность - это проект сообщества istio и связанные с ним. В экосистеме Red Hat этот 
функционал реализован в операторе Kubernetes, получившим название OpenShift Service Mesh. Последний включает 
в себя не только возможности istio, но и позволяет трассировать вызовы микросервисов, используя Jaeger, имеет 
механизм обнаружения сервисов, и представлять графически их взаимосвязи, используя Kiali.

Тем не менее, начнем с простого. Quarkus позволят просто, из коробки, без дополнительного кодирования, 
получить защищенную точку входа, представляющего пользовательский сервис. Для этого необходимо иметь частный 
и публичный ключ, а в правильных системах цепочку сертификатов, для безопасной и удобной работы. Существует 
набор из пяти статей по организации своего собственного удостоверяющего центра 
https://devcentral.f5.com/s/articles/building-an-openssl-certificate-authority-introduction-and-design-considerations-for-elliptical-curves-27720. 

Для выполнения заданий по каждой главе, которая предусматривает защищенное соединение, можно использовать 
сертификаты из папки `certs`, находящейся в корне проекта. Quarkus использует возможности JVM по работе с 
хранилищами ключей, и без дополнительных действий воспринимает следующие форматы хранилища: jks, jcek, pxf и x509. 
Мы будем использовать защищенное соединение, требующее достоверности только со стороны сервера, то есть нашего 
приложения. Такое соединение называется one-way SSL connection. Для использования двусторонней проверки и 
подтверждения, имеет смысл переходить на механизмы, предоставляемые istio или OpenShift Service Mesh, такой 
тип соединения часто называют mTLS (mutual TLS).

Для того, чтобы гарантировать со стороны приложения безопасное соединение, необходимо добавить в файл настроек 
несколько строк, указывающих на расположение сертификатов и указать порт, на котором приложение будет ожидать 
соединения. Традиционно все настройки имеют в названии буквы SSL, но этот протокол устарел и вместо него 
используется TLS. Тем не менее необходимо дополнить файл `app/src/main/resources/application.properties’ следующими строками:
```
quarkus.http.ssl-port=8443
quarkus.http.ssl.certificate.key-store-password=changeit
%dev.quarkus.http.ssl.certificate.key-store-file=../../certs/quarkus-demo.pfx
%test.quarkus.http.ssl.certificate.key-store-file=../certs/quarkus-demo.pfx
```
Две последних строки имеют префиксы %dev и %test, которые означают, что эти описания будут применены на этапе 
разработки или запуска юнит-тестов. Эти префиксы отражают название профиля, который запускает фремворк в зависимости 
от перечисленных выше условий. Существует еще один предопределенный профиль запуска - prod, который используется в 
промышленном режиме работы приложения, и активируется по умолчанию. Если префикс отсутствует, то это означает, что 
данный параметр будет иметь силу для всех профилей. Есть возможность свой собственный профиль запуска. 

Сейчас и в дальнейшем, все запуски maven необходимо производить из каталога `app’,
```
cd $WS/quarkus-demo/app
mvn quarkus:dev &

curl -kv --resolv quarkus:8443:127.0.0.1 https://quarkus:8443/hello ; echo
[...]
* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384
* ALPN, server accepted to use h2
[...]
* Using HTTP2, server supports multi-use
* Connection state changed (HTTP/2 confirmed)
[...]

fg
```
При работе через защищенный канал все современные приложения, в том числе и браузер будут пытаться использовать 
протокол HTTP/2, что видно в строках лога. Для дальнейшего удобства и работы через браузер, необходимо добавить 
запись `quarkus’, указывающую на локальных хост (127.0.0.1) в /etc/hosts. Также импортировать в операционную 
систему или браузер корневой сертификат `custom-ca.pem’ удостоверяющего центра из папки `certs’.

Исходный код, готовый к сборке и запуску находится в ветке b-step-02 репозитория https://github.com/e2e-openshift-demos/quarkus-demo.

## Глава 3 - Подключение к вычислительной сети данных (datagrid)

Это одна из основных и объемных частей учебника и разделена на четыре параграфа. Первый посвящен подготовке 
локального сервера datagrid, второй - разработке бизнес-логики, третий созданию безопасного соединения, и 
заключительный четвертый - развертыванию сервера datagrid на OpenShift с помощью оператора.

Почему используется datagrid сервер? Дело в том, что современных реалиях приложения должны работать не только надежно,
но и быстро, а также потреблять как можно меньше ресурсов. Таким образом приложение можно разместить в облачной 
инфраструктуре, а так как оно потребляет мало ресурсов, то это сказывается и на стоимости эксплуатации. А так как 
оно еще стартует быстро, то можно дополнительно сэкономить, запуская его только по требованию, и легко адаптировать 
к изменяющейся нагрузке. Datagrid, в свою очередь, имеет в промышленном состоянии распределенную конфигурацию и работает 
через надежный отказоустойчивый протокол, а запросы выполняет быстро и, как правило, параллельно, что сказывается и на
скорости ответов приложения.

### Параграф 1 - Подготовка локального сервера datagrid

Благодаря контейнерным технологиям и наличию готового образа, существует возможность запустить локальный сервер datagrid. 
Для этого необходимо выбрать какой образ загрузить, как обычно существует версия от сообщества и продукт от Red Hat.

Также образ запускается на любом OCI-совместимой среде выполнения. В учебнике используется podman, который имеет 
следующие преимущества:
- обеспечивает работу с контейнерами, не требуя повышенных привилегий
- имеет свое пространство для хранения образов (по умолчанию ~/.local/share/containers)
- легок и быстр, так как не требует специального системного процесса
Те, кто привык к Docker также имеют возможность запустить эти OCI-совместимые образы.

Как и в случае с фреймворком Quarkus существуют различные варианты сборок:
- стандартный образ от сообщества, на данный момент это версия 11 (docker.io/infinispan/server)
- основанный на Quarkus сервер, собранный под машинный код Intel x86_64 для операционной системы 
Linux (quay.io/infinispan/server-native)
- продукт Red Hat Datagrid версии 8, обратите внимание, что это версия продукта, а не Infinispan с
ервера туда входящего, более подробно относительно версий всех компонентов можно ознакомиться 
по адресу https://access.redhat.com/articles/4933371 

Версию от сообщества можно загрузить следующим образом:
```
$ podman run --rm -ti infinispan/server
```
Аналогично можно загрузить и продукт Red Hat Datagrid:
```
$ podman login -u <username> registry.redhat.io
$ podman run --rm -ti registry.redhat.io/datagrid/datagrid-8-rhel8
```
В обоих случаях, после окончания загрузки, сервер запустится в течение 8-10 секунд.

В учебнике в качестве локального сервера datagrid, используется основанный на Quarkus образ. 
Загрузить и запустить его можно, выполнив команду:
```
$ podman run --rm -ti quay.io/infinispan/server-native
```
Обратите внимание, что сервер запуститься примерно в два раза быстрее (около 5 секунд), 
а образ также имеет меньший размер - примерно на 40%.

После того, как образ загрузился и был протестирован его запуск. В его конфигурацию необходимо добавить 
настройки пользователей. В промышленном варианте необходимо интегрировать его для использования системных 
учетных записей из каталогов. Для целей разработки и тестирования можно быстро сконфигурировать список 
пользователей через настроечный файл, как показано ниже:
```
cd $WS/quarkus-demo
mkdir jdg && cd jdg
cat > identities.yaml << EOF
credentials:
- username: developer
  password: dIRs5cAAsHIeeRIL
- username: operator
  password: uMBo9CmEdEduYk24
EOF
podman run --rm -ti \
    -p 11222:11222 \
-e IDENTITIES_PATH=/user-config/identities.yaml \
-v $(pwd)/identities.yaml:/user-config/identities.yaml:z,ro \
infinispan/server-native
```
Локальный сервер datagrid готов к использованию.

Исходный код, готовый к сборке и запуску находится в ветке b-step-03_1 репозитория https://github.com/e2e-openshift-demos/quarkus-demo. 

### Параграф 2 - разработка бизнес-логики.

В учебнике используется Microsoft VS Code - легкая, быстрая и расширяемая интегрированная среда разработчика. 

Для подключения в maven проект расширения для работы с datagrid необходимо выполнить команду:
```
cd $WS/quarkus-demo/app
mvn quarkus:add-extension -Dextensions="infinispan-client"
```

Основы по работе с datagrid во фреймворке Quarkus можно почерпнуть из обучающей статьи https://quarkus.io/guides/infinispan-client. 
В данном учебнике в качестве демонстрационного объекта данных используется QuarkusDemoDataObject с двумя 
атрибутами: "name" строчного типа, и "id" типа java.util.UUID, который он наследует от AbstractDataObject. 
Исходный код находится в папке src/main/java/com/redhat/codeready/model. В примере будет использоваться конфигурируемое 
имя области хранения (cache name)  datagrid, соответственно, для этого необходимо использовать инициализатор, 
код которого находится в CacheInitializer. Для определения имени cache name, необходимо добавить в файл свойств 
приложения параметр `application.cache.name’. Стандартные операции создания, изменения, получения, удаления (CRUD) 
над объектом QuarkusDemoDataObject выполняются сервисом QuarkusDataService, а доступ к сервису осуществляется через 
QuarkusResource по протоколу REST.

Для доступа к datagrid серверу необходимо добавить соответствующие параметры в файл свойств приложения:
```
application.cache.name=quarkus-data-object

# quarkus infinispan properties
quarkus.infinispan-client.auth-username=developer
quarkus.infinispan-client.auth-password=dIRs5cAAsHIeeRIL
quarkus.infinispan-client.client-intelligence=BASIC
quarkus.infinispan-client.sasl-mechanism=DIGEST-MD5
quarkus.infinispan-client.server-list=datagrid:11222
```
Аналогично шагу 2, необходимо добавить в `/etc/hosts’ запись `datagrid’, указывающую на локальный хост.

Так как используется datagrid, то это означает сетевое взаимодействие, что влечет за собой сериализацию экземпляров 
объектов. Соответственно, необходимо также предусмотреть реализацию механизма сериализации-десериализации. 
Расширение Quarkus для работы с datagrid-сервером может использовать три вида сериализации:
- JBoss Serialization, этот механизм устарел и скоро перестанет быть доступным
- Java Serialization API, этот механизм поддерживается, хотя не отличается быстродействием, но он прост, 
при необходимости легко дополняется для ускорения процесса сериализации и хорошо знаком Java-программистам
- ProtoBuffer - это механизм, разработанный в Google, имеет ряд неоспоримых преимуществ, таких как независимостью 
от языка реализации, гибкостью, скоростью работы, является основой реализации для gRPC-вызовов, которые являются 
расширением протокола HTTP/2. Современные приложения и сервисы массово начинают использовать эту технологию. 
Quarkus и Infinispan, который является основой datagrid, используют именно ProtoBuf по умолчанию.

Несмотря на все очевидные преимущества, ProtoBuf из-за своей гибкости предусматривает некоторые дополнительные шаги 
по его настройке. Может возникнуть соблазн использовать старый и привычный механизм Java Serialization API, в этом 
случае необходимо указать Quarkus на его использование. Однако, это возможно сделать только в конфигурационном 
файле протокола удаленного доступа (hotrod-client.properties) к datagrid серверу. Файл должен находится в каталоге 
META-INF, в пути к классам Java:
```
infinispan.client.hotrod.marshaller=org.infinispan.commons.marshall.JavaSerializationMarshaller
infinispan.client.hotrod.java_serial_whitelist=com.redhat.codeready.model.,java.util.UUID
```
JUnit тесты находятся в QuarkusResourceTest.

Проверить работу можно командой:
```
cd $WS/quarkus-demo/app
mvn test
```

Исходный код, готовый к сборке и запуску находится в ветке b-step-03_2 репозитория https://github.com/e2e-openshift-demos/quarkus-demo.

### Параграф 3 - Защита соединения с сервером datagrid

Защита соединения начинается с настройки сервера datagrid. Это можно сделать дальнейшей настройкой параметров,
как показано в примере ниже:
```
$ cat > jdg-config.yaml << EOF
---
keystore:
  password: changeit
  path: /user-config/server.pfx
  type: PFX
  alias: 1
EOF
$ podman run -ti --rm -p 11222:11222 \
--name datagrid \
-e CONFIG_PATH=/user-config/config.yaml \
-e IDENTITIES_PATH=/user-config/identities.yaml \
-v identities.yaml:/user-config/identities.yaml:z,ro \
-v ../certs/datagrid.pfx:/user-config/server.pfx:ro,z \
-v jdg-config.yaml:/user-config/config.yaml:ro,z infinispan/server-native
```
Для большего удобства последовательность команд и некоторые другие настройки инкапсулированы в сценарии shell, 
который будет использоваться для запуска локального сервера datagrid в рамках учебника (скрипт и необходимые 
файлы находятся в ветке b-step-03_3).
```
bash $WS/quarkus-demo/jdg/run.sh

```
Работоспособность проверяется командой:
```
curl -kv https://datagrid:11222

[...]
* SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384
* ALPN, server accepted to use h2
* Server certificate:
[...]
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
< HTTP/2 307
< location: /console/welcome
[...]
```
Далее, необходимо настроить приложение Quarkus, 
Настройки, находящиеся в файле hotrod-client.properties имеют силу только на этапе сборки приложения, 
а конфигурация безопасного соединения на текущий момент возможна только там. Это неприемлемо для промышленного 
использования в облачных контейнерных средах (Kubernetes, OpenShift), так как настройки в виде конфигурационных 
файлов и других сущностей осуществляются через ConfigMap или Secret. Для решения этого затруднения придется 
задавать конфигурацию подключения к серверу datagrid программно. Это осуществляется в двух Java-классах, 
где первый DataGridConfiguration аннотацию для описания подключения, а второй DatagridClientConfigj реализует 
фабрику подключений, основываясь на параметрах, заданных в файле конфигурации приложения. Используя механизм 
аннотаций необходимо заменить инъекцию менеджеров подключения (RemoteCacheManager) во всех классах: 
CacheInitializer, QuarkusDataService и CacheLoader. А также добавлять необходимые параметры в файл конфигурации 
приложения:
```
%dev.application.infinispan-client.trust_store_file_name=../../certs/custom-ca.pem
%test.application.infinispan-client.trust_store_file_name=../certs/custom-ca.pem
application.infinispan-client.sni=datagrid
```
Проверить работоспособность можно, запустив тесты. ОБратите внимание на строку лога, в которой видно, что п
рименяется конфигурация с безопасным соединением `infinispan.client.hotrod.use_ssl=true’. Также файл 
`hotrod-client.properties’ в дальнейшем не понадобится.
```
mvn clean test
```

Исходный код, готовый к сборке и запуску находится в ветке b-step-03_3 репозитория https://github.com/e2e-openshift-demos/quarkus-demo. 

### Параграф 4 - Развертывание сервера datagrid на OpenShift

Для комфортного взаимодействия с сервисами, развернутыми в OpenShift, желательно заменить самоподписанные
сертификаты сервиса маршрутизации OpenShift на выпущенные каким-либо провайдером, корпоративные, 
или воспользоваться тестовыми, которые находятся в каталоге `certs/openshift-ingress.pxf’. Процесс замены 
сертификатов состоит из двух простых шагов и описан в разделе документации 
https://docs.openshift.com/container-platform/4.5/security/certificates/replacing-default-ingress-certificate.html

Самым простым и стандартным способом развернуть сервер datagrid на OpenShift является путь использования оператора. 
В магазине приложений традиционно имеется версия оператора и, соответственно, сервера от сообщества и продукт от Red Hat.
Процесс развертывания состоит из двух частей, первая - это разрешение оформить подписку на сервис оператора datagrid, 
а вторая - создание сервера. Для первого пункта необходимы некоторые привилегии. Развернуть оператор и создать сервер 
можно как через Web-консоль, так и через командную строку с помощью средства openshift-client (oc). Ниже показан пример 
для командной строки:
```
$ cd $WS/quarkus-demo/jdg
$ oc login -u developer -p developer https://api.crc.testing:6443
$ oc new-project datagrid
$ oc --as system:admin create -f infinispan-subscription.yaml
$ oc create -f infinispan-instance.yaml
$ # sleep 10
$ # oc -n datagrid create route passthrough --service quarkus-test
```
Последняя команда создаст маршрут к серверу datagrid. Для дальнейшего удобства можно воспользоваться сценарием s
hell `datagrid-operator-setup.sh’, который выполнит настройки для защищенного подключения, создаст подписку и сервер 
datagrid с двумя репликами, а также будет использовать не стандартный образ, а основанный на Quarkus режим компиляции в машинный код.

Далее, необходимо исправить настройки подключения к серверу в файле свойств приложения:
```
# quarkus.infinispan-client.server-list=datagrid:11222
# application.infinispan-client.sni=datagrid
quarkus.infinispan-client.server-list=quarkus.apps-crc.testing:443
application.infinispan-client.sni=quarkus-external-datagrid.apps-crc.testing
```
Выполнение тестов должно подтвердить правильность выполнения описанных действий.

Исходный код, готовый к сборке и запуску находится в ветке b-step-03_4 репозитория https://github.com/e2e-openshift-demos/quarkus-demo. 

## Глава 4 - Компиляция приложения в машинный код

Отличительной чертой Quarkus является возможность использования Graal VM для получения минимального по размеру 
и максимального по производительности приложения, не зависящего от наличия JVM в образе контейнера. 
Стандартная генерация шаблона проекта сразу включает настройки (отдельный профиль в pom.xml) для сборки приложения 
в машинный код. Но этот профиль подразумевает установленное и настроенное окружение Graal VM. Проще всего это сделать 
используя готовый образ контейнера с предустановленным и настроенным окружением.  Однако, если использовать новые 
дистрибутивы Fedora, RHEL 8, то там отсутствует среда выполнения, основанная на Docker, и заменена на более легкий 
и разделенные по функционалу компоненты. Для успешной сборки в файл описания проекта maven необходимо добавить 
специальный параметр, уточняет какое средство для запуска контейнера, как приведено ниже:
```
<quarkus.package.type>native</quarkus.package.type>
<quarkus.native.container-runtime>podman</quarkus.native.container-runtime>
```
Если при подготовке шаблона использовать сценарий из Главы 1, то эти параметры уже будут установлены.
Для запуска необходимо выполнить команду сборки проекта, для примера:
```
mvn package -Pnative
```
При сборке произойдет следующее: в дополнение к стандартным шагам сборки, расширение maven само выполнит загрузку 
необходимого образа контейнера, и на выходе создаст готове для выполнения приложение, которое можно запустить 
на операционной системе (Fedora, RHEL, Ubuntu,..), на которой не установлено окружение Java. Сам образ будет иметь 
размер сопоставимый с приложением, полученным при генерации на языке Go. Процесс генерации машинного кода, включает 
несколько шагов, выполняемых автоматически, которые анализируют бакт-код, ссылки на внешние библиотеки, параметры 
сериализации и т.д. Этот процесс ресурсоемкий и может длиться несколько минут, вплоть до 10, Завии зависит от мощности 
компьютера. Например, на 12-ядерном сервере занимает около 3 минут.

Для запуска приложения ему необходимо иметь доступ к файлу application.properties. Quarkus позволяет переопределить 
настройки, что важно для облачных сред. Фреймворк будет искать настройки в каталоге `config’ относительно пути, 
где расположено приложение. Более подробно с настройкой конфирмации можно ознакомиться по адресу 
https://quarkus.io/guides/config. Далее, если при запуске приложения не указывать профиль, то по умолчанию будет 
использоваться промышленный, таким образом необходимо дополнить файл настроек:
```
quarkus.http.ssl.certificate.key-store-file=../../certs/quarkus-demo.pfx
application.infinispan-client.trust_store_file_name=../../certs/custom-ca.pem
```
В Промышленной среде эти пути будут отличаться.
Как известно maven по умолчанию помещает все собранные артефакты в каталог `target’. Таким образом чтобы приложение 
не только запустилось, но и исправно работало необходимо перейти в каталог `target’, создать там папку `config’ 
и скопировать в нее актуальный для окружения файл настроек приложения, как приведено ниже
```
cd $WS/quarkus-demo/app/target
mkdir -p config && cd config
ln -s ../../src/main/resources/application.properties . && cd ..
./quarkus-demo-1.0-SNAPSHOT-runner-native
```
На скорость загрузки и готовности приложения. Это время составит примерно от одной до двух десятых секунды. 
Для первой попытки замечательный результат. 

Если попытаться обратиться к функциям приложения по работе с данными, то возникнут исключительные ситуации 
по сериализации. Как показано в примере ниже:
```
curl -v --resolve quarkus-demo.quarkus-demo:8443:127.0.0.1 https://quarkus-demo.quarkus-demo:8443/quarkus/11111111-0E00-3333-4444-555555555555
```
Это плата за компиляцию в машинный код. Многие методы по работе с Java Reflection API, если явно не указано явно 
в настройках приложения, не работают корректно или вообще не поддерживаются.

Этот случай демонстрирует, как говорилось выше в главе про выбор механизмов сериализации, к каким последствиям может 
привести выбор неправильного решения для вашего кода и приложения в целом. Таким образом, необходимо внести улучшения 
в реализация механизма сериализации. Для этого необходимо реализовать два объекта (QuarkusDemoDataObjectMarshaller, UUIDMarshaller) 
типа сериализатора, объект инициализации контекста ((DataObjectSerializationContextInitializer)) и указать на использование 
нового механизма в конфигурации соединения с сервером datagrid (DatagridClientConfig). Новый механизм будет использовать 
технологию ProtoBuffer, который вводит новую сущность - файл описания сериализуемых объектов. В учебнике используется файл 
`dataiobject.proto’. Также сам протокол HotRod нуждается в .proto описании своих внутренних объектов. Эти описания находятся 
в src/main/resources/META-INF/dataobject.proto и src/main/resources/org/infinispan/protostream. Более того, механизм 
предложенный учебнике на данный момент является единственным для реализации сериализации ProtoBuf для внешних сущностей 
типа java.util.UUID. Более подробно с темой сериализации для datagrid можно ознакомиться в стандартном учебнике по Quakrus 
https://quarkus.io/guides/infinispan-client#user-written-serialization. В файл конфигурации приложения необходимо добавить 
свойство для сборки в машинный код, ссылающееся на файлы ProtoBuf:
```
quarkus.native.resources.includes=**/*.proto
```

Далее можно собрать и протестировать приложение.
```
mvn package -Pnative
cd target 
./quarkus-demo-1.0-SNAPSHOT-runner
```
Проверить ответ приложения через бразуер (https://127.0.0.1:8443/quarkus/11111111-0E00-3333-4444-555555555555) или командную строку:
```
curl -v --resolve quarkus-demo.quarkus-demo:8443:127.0.0.1 https://quarkus-demo.quarkus-demo:8443/quarkus/11111111-0E00-3333-4444-555555555555 ; echo
[...]
* TLSv1.3 (OUT), TLS app data, [no content] (0):
> GET /quarkus/11111111-0E00-3333-4444-555555555555 HTTP/2
> Host: quarkus-demo.quarkus-demo:8443
> User-Agent: curl/7.61.1
[...]
* Connection #0 to host quarkus-demo.quarkus-demo left intact
{"id":"11111111-0e00-3333-4444-555555555555","version":"d8529ef2-9996-45ed-a3c3-e916494fab9e","name":"TEST_GET"}
```

Исходный код, готовый к сборке и запуску находится в ветке b-step-04 репозитория https://github.com/e2e-openshift-demos/quarkus-demo. 

## Глава 5 - Развертывание проекта на OpenShift

Quarkus имеет расширения для работы с облачными средами типа Kubernetes. В учебнике будет использоваться 
расширение для OpenShift, которое было подключено сразу, на этапе создания шаблона проекта. Изначально,
чтобы во время сборки проекта, приложение было развернуто на OpenShift необходимо добавить лишь свойства, на это указывающие:
```
quarkus.kubernetes-client.trust-certs=true
quarkus.s2i.base-jvm-image=registry.access.redhat.com/ubi8/openjdk-11

# Automatically expose quarkus route
quarkus.openshift.expose=true

quarkus.kubernetes.deployment-target=openshift
```
Они были автоматически добавлены при генерации шаблона сценарием shell `bootstrap.sh’, и для того чтобы произошло 
развертывание необходимо лишь указать параметр при запуске сборки. Для этого необходимо создать проект в OpenShift 
и переключить контекст на использование этого проекта. Обратите внимание на то, что приложение будет развертываться 
всегда в текущий контекст.
```
oc login -u developer
oc new-project quarkus-demo-test # контекст переключится автоматически
```
Выполняется сборка следующим образом:
```
$ cd $WS/quarkus-demo/app
$ mvn package -Dquarkus.kubernetes.deploy=true
```
Однако, в файле application.properties существуют ссылки на внешние ресурсы, которых нет в облачной среде. 
Необходимо дать инструкции расширению сборки, чтобы оно сформировало необходимые манифесты для загрузки в OpenShift:
```
quarkus.openshift.working-dir=/deployments
quarkus.openshift.secret-volumes.server-certs.secret-name=quarkus-demo-certs
quarkus.openshift.mounts.server-certs.path=/deployments/certs/server.pfx
quarkus.openshift.mounts.server-certs.sub-path=server.pfx

quarkus.openshift.secret-volumes.ca-store.secret-name=custom-ca
quarkus.openshift.mounts.ca-store.path=/deployments/certs/ca.pem
quarkus.openshift.mounts.ca-store.sub-path=ca.pem

quarkus.openshift.config-map-volumes.quarkus-config.config-map-name=quarkus-application-config
quarkus.openshift.mounts.quarkus-config.path=/deployments/config
```
Здесь указаны полные пути к сертификатам, где их будет искать приложение, а также ссылки на секреты и файлы 
конфигурации, которые будут указан в манифестах. Необходимо создать реальные экземпляры этих секретов и файлов 
конфигурации в облачной среде, для этого можно воспользоваться скриптами из каталога `utils’:
```
cd $WS/quarkus-demo/utils
APP_NS=quarkus-demo-test SECRET_FILE_NAME=server.pfx bash create-secret.sh quarkus-demo-certs ../certs/quarkus-demo.pfx
APP_NS=quarkus-demo-test SECRET_FILE_NAME=ca.pem bash create-secret.sh custom-ca ../certs/custom-ca.pem
APP_NS=quarkus-demo-test CONFIG_FILE_NAME=application.properties bash create-cm.sh quarkus-application-config ../app/src/main/resources/prod-application.properties
```
Для описания конфигурации приложения используется очищенный от отладочных и времени сборки свойств `prod-application.properties’. 
На этом этапе осуществляется, так называемая, бинарная сборка (binary build), то есть OpenShift не будет собирать 
приложение из исходного кода, Данный подход очень удобен для ведения интерактивной разработки, когда код собирается 
быстро на локальном компьютере, а OpenShift только выполняет сборку и запуск образа контейнера. Для этого необходимо 
настроить механизм S2I `.s2i/invironment’ на выполнение именно бинарной сборки, указав какие артефакты копировать в результирующий образ:
```
ARTIFACT_COPY_ARGS=-p -r target/lib/ target/*-runner.jar
```
Запустить сборку и развертывание можно командой:
```
cd $WS/quarkus-demo/app
mvn package -Dquarkus.kubernetes.deploy=true
```
Ознакомиться с процессом сборки и развертывания можно в консоли OpenShift для администратора 
https://console-openshift-console.apps-crc.testing/k8s/ns/quarkus-demo-test/buildconfigs или 
разработчика https://console-openshift-console.apps-crc.testing/topology/ns/quarkus-demo-test/graph

Исходный код, готовый к сборке и запуску находится в ветке b-step-05 репозитория https://github.com/e2e-openshift-demos/quarkus-demo. 

## Глава 6 - Конвейер CI/CD

Конвейер Tekton является универсальным средством для запуска процесса CI/CD в облачных средах, основанных на Kubernetes. 
Отличительными чертами которого являются:
- отсутствие выделенного сервера сборки, эту роль берет на себя механизм операторов Kubernetes
- легковесность, это обеспеспечивает за счет парадигмы “выполнение по запросу”
- независимость этапов сборки друг от друга и их повторяемость за счет изоляции в контейнерах, параметризированных входными данными
- возможность реализации каждого шага пользовательским способом, путем указания в качестве конкретного шага готового и 
известного действия или преопределенного пользователем.

Для инициации возможности запуска конвейера на базе Tekton, необходимо воспользоваться магазином приложений OpenShift и 
установить оператор, реализующий функционал обработки конвейера. Процесс установки мало отличается от установки любого 
другого оператора, в том числе и рассмотренного выше оператора Datagrid, и подробно описан в соответствующей главе 
документации OpenShift https://docs.openshift.com/container-platform/4.5/pipelines/installing-pipelines.html 

После установки оператора самым простым способом получения шаблона конвейера является указать необходимость создания оного 
при сборке приложения из исходного кода, используя механизм OpenShift BuildConfig в Web-консоли OpenShift. или используя 
OpenShift PipelineBuilder - еще одну возможность OpenShift Web-консоли (пример в видеоролике https://youtu.be/iReb5osQg24).
В данном учебнике используется модифицированное, основанное на созданном из шаблона, описание конвейера, состоящего из трех задач:
- инициализация - создает из подготовленных манифестов из каталога `app/openshift/manifest’ соответствующие объекты OpenShift
- сборка - использует полнофункциональную S2I сборку для получения образа контейнера для Quarkus-приложения
- статус - запускает процесс наблюдения за результатом развертывания вновь собранного приложения, в результате неудачи возврат 
к предыдущему удачному развертыванию.
Манифесты создания конвейера находятся в каталоге `app/openshift/pipeline’ и состоят из двух файлов:
- 20-pipeline.yaml - описание задач конвейера (инициализация, сборка, статус), параметров (имя приложения) и ссылок на внешние ресурсы
- 30-pr.yaml - описание внешних ресурсов (параметры репозитория исходного кода и параметры реестра образов)
Последний необходимо модифицировать в соответствие с конкретными параметрами. Применить манифесты к текущему контексту можно, 
как показано ниже:
```
cd $WS/quarkus-demo/app/openshift/pipeline
oc new-project quarkus-demo --display-name 'Quarkus demo with Tekton pipeline'
oc apply -f 20-pipeline.yaml
``` 
Проинспектировать результат можно в Web-консоли OpenShift 
https://console-openshift-console.apps-crc.testing/k8s/ns/quarkus-demo/tekton.dev~v1alpha1~Pipeline. 
Это абсолютный путь, который со стабилизацией Tekton CR, будет меняться. В общем случае увидеть и запустить 
конвейер можно через консоль разработчика https://console-openshift-console.apps-crc.testing/topology/ns/quarkus-demo/ 
(или администратора) и выбрать раздел Pipelines.

Для удобства и упрощения манифестов, можно указать сборщику, чтобы он собрал результат во всеобъемлющий архив
```
quarkus.package.uber-jar=true
```
И отменить копирование всех библиотек для S2I:
```
# ARTIFACT_COPY_ARGS=-p -r target/lib/ target/*-runner.jar
```

Разово запустить сборку также проще всего через Web-консоль.

Далее, Tekton pipeline, как и Jenkins pipeline, как и любую сборку OpenShift Build можно запустить по событию в триггере,
в качестве инициатора может выступать SCM на основе протокола Git (GitHub, GitLab, Gogs, и т.д.), единственное условие 
они должны иметь возможность запустить триггер через обращение по специальному URL.

Факультативно, можно установить в OpenShift с помощью оператора простейшую SCM, например Gitea, загрузить туда исходные 
коды проекта и настроить Web-hook. Манифесты для установки оператора можно найти в каталоге `gitea’.

Настройка средства обработки событий производится, как приведено ниже:
```
$ cd $WS/quarkus-demo/app/openshift/pipeline
$  oc apply -f 03-tb.yaml
$  oc apply -f 05-tt.yaml
$  oc apply -f 11-el.yaml
$  oc apply -f 12-el-route.yaml
$ oc get route el-quarkus-demo -o jsonpath='{ "https://" }{ .spec.host }{ "\n" }'
```
Заключительная команда покажет точку доступа к обработчику, ее надо указать в Web-hook средства управления исходным кодом.
Использование альтернативных Gitea средств поддерживается, необходимо лишь привести в соответствие описания привязок, 
которые находятся в файле `03-tb.yaml’.

Обработчик триггера будет оставлять для каждого срабатывания ресурсы (pipeline resource) для атрибутов git и образа 
контейнера, чтобы можно было воспроизвести в дальнейшем любую ситуацию. 
 
Исходный код, готовый к сборке и запуску находится в ветке b-step-06 репозитория https://github.com/e2e-openshift-demos/quarkus-demo.

## Глава 7 - Serverless

Для работы с без серверными микросервисами, необходимо установить оператор, согласно инструкции из документации 
по OpenShift https://docs.openshift.com/container-platform/4.4/serverless/installing_serverless/installing-openshift-serverless.htm.
Quarkus при сборке приложения генерирует необходимые для развертывания манифесты, для этого в файле свойств приложения 
необходимо указать это в соответствующем параметре:
```
quarkus.kubernetes.deployment-target=openshift,knative
```
В результате сборки дополнительно ко всему появился файл `target/kubernetes/knative.yml’ который используется для описания 
serverless сервисов. Конечный результат приведен в `openshift/manifest/33-knative.yaml’.манифест применяется командой
```
cd $WS/quarkus-demo/app/openshift/manifest
oc apply -f 33-knative.yaml
```
В результате применения манифеста, в соответствующем разделе 
https://console-openshift-console.apps-crc.testing/k8s/ns/quarkus-demo/serving.knative.dev~v1~Service появятся описания сервиса, 
ревизии и маршрута к нему. После того, как ревизия будет проверена (она существует, запускатся и отвечает), сервис перейдет 
в состояние доступности. В нему можно обратиться по адресу http://quarkus-demo-k-quarkus-demo.apps-crc.testing.

Исходный код, готовый к сборке и запуску находится в ветке b-step-07 репозитория https://github.com/e2e-openshift-demos/quarkus-demo. 

## Глава 8 - Дополнение приложения тестами готовности и метриками

Quarkus имеет поддержку Eclipse Microprofile и этот функционал легко добавить к имеющемуся приложению. Для реализации простых 
проверок готовности необходим добавить в описание класса аннотацию @Liveness или @Readiness и реализовать интерфейс HealthCheck. 
Более подробно это описано в соответствующем учебнике по Quarkus - https://quarkus.io/guides/microprofile-health. Фреймворк также 
поддерживает и работу с метриками - https://quarkus.io/guides/microprofile-metrics. 
Конечно же можно разработать и свои механизмы описания готовности и статистики. 

Исходный код, готовый к сборке и запуску находится в ветке b-step-08 репозитория https://github.com/e2e-openshift-demos/quarkus-demo. 

## Глава 10 - Управление жизненным циклом приложения с помощью оператора

## Глава 11 - Фронтенд
